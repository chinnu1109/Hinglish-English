{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","gpuClass":"standard","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8104297,"sourceType":"datasetVersion","datasetId":4786343},{"sourceId":8308310,"sourceType":"datasetVersion","datasetId":4935069},{"sourceId":168429233,"sourceType":"kernelVersion"}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"- Remove non alphanumeric characters for simple training","metadata":{"id":"VmYGVziz50tu"}},{"cell_type":"code","source":"from transformer import Transformer \nimport torch\nimport numpy as np","metadata":{"id":"FOwRggVcwtzP","execution":{"iopub.status.busy":"2024-05-05T04:50:13.368982Z","iopub.execute_input":"2024-05-05T04:50:13.369757Z","iopub.status.idle":"2024-05-05T04:50:13.385492Z","shell.execute_reply.started":"2024-05-05T04:50:13.369708Z","shell.execute_reply":"2024-05-05T04:50:13.384607Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"hinglish_file = '/kaggle/input/datasets-from-github/Hinglish.txt' \nenglish_file = '/kaggle/input/datasets-from-github/English.txt' \n\n\nSTART_TOKEN = '<START>'\nPADDING_TOKEN = '<PADDING>'\nEND_TOKEN = '<END>'\n\nenglish_vocabulary = [START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', \n                        '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n                        ':', '<', '=', '>', '?', '@',';',\n                        '[', '\\\\', ']', '^', '_', '`', \n                        'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n                        'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', \n                        'y', 'z', \n'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L',\n'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X',\n'Y', 'Z',\n                        '{', '|', '}', '~', PADDING_TOKEN, END_TOKEN]\n\nhinglish_vocabulary = [START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', \n                        '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n                        ':', '<', '=', '>', '?', '@',';',\n                        '[', '\\\\', ']', '^', '_', '`', \n                        'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n                        'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', \n                        'y', 'z', \n'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L',\n'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X',\n'Y', 'Z',\n                        '{', '|', '}', '~', PADDING_TOKEN, END_TOKEN]","metadata":{"id":"6TApzOj5xCwR","execution":{"iopub.status.busy":"2024-05-05T04:50:14.411960Z","iopub.execute_input":"2024-05-05T04:50:14.412357Z","iopub.status.idle":"2024-05-05T04:50:14.423672Z","shell.execute_reply.started":"2024-05-05T04:50:14.412328Z","shell.execute_reply":"2024-05-05T04:50:14.422709Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"index_to_english = {k:v for k,v in enumerate(english_vocabulary)}\nenglish_to_index = {v:k for k,v in enumerate(english_vocabulary)}\n\nindex_to_hinglish = {k:v for k,v in enumerate(hinglish_vocabulary)}\nhinglish_to_index = {v:k for k,v in enumerate(hinglish_vocabulary)}","metadata":{"id":"gA8ESmCrNoc7","execution":{"iopub.status.busy":"2024-05-05T04:50:15.410618Z","iopub.execute_input":"2024-05-05T04:50:15.411309Z","iopub.status.idle":"2024-05-05T04:50:15.416597Z","shell.execute_reply.started":"2024-05-05T04:50:15.411275Z","shell.execute_reply":"2024-05-05T04:50:15.415585Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print(index_to_english)\nprint(index_to_hinglish)","metadata":{"execution":{"iopub.status.busy":"2024-05-05T04:50:16.346270Z","iopub.execute_input":"2024-05-05T04:50:16.346621Z","iopub.status.idle":"2024-05-05T04:50:16.352045Z","shell.execute_reply.started":"2024-05-05T04:50:16.346593Z","shell.execute_reply":"2024-05-05T04:50:16.351085Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"{0: '<START>', 1: ' ', 2: '!', 3: '\"', 4: '#', 5: '$', 6: '%', 7: '&', 8: \"'\", 9: '(', 10: ')', 11: '*', 12: '+', 13: ',', 14: '-', 15: '.', 16: '/', 17: '0', 18: '1', 19: '2', 20: '3', 21: '4', 22: '5', 23: '6', 24: '7', 25: '8', 26: '9', 27: ':', 28: '<', 29: '=', 30: '>', 31: '?', 32: '@', 33: ';', 34: '[', 35: '\\\\', 36: ']', 37: '^', 38: '_', 39: '`', 40: 'a', 41: 'b', 42: 'c', 43: 'd', 44: 'e', 45: 'f', 46: 'g', 47: 'h', 48: 'i', 49: 'j', 50: 'k', 51: 'l', 52: 'm', 53: 'n', 54: 'o', 55: 'p', 56: 'q', 57: 'r', 58: 's', 59: 't', 60: 'u', 61: 'v', 62: 'w', 63: 'x', 64: 'y', 65: 'z', 66: 'A', 67: 'B', 68: 'C', 69: 'D', 70: 'E', 71: 'F', 72: 'G', 73: 'H', 74: 'I', 75: 'J', 76: 'K', 77: 'L', 78: 'M', 79: 'N', 80: 'O', 81: 'P', 82: 'Q', 83: 'R', 84: 'S', 85: 'T', 86: 'U', 87: 'V', 88: 'W', 89: 'X', 90: 'Y', 91: 'Z', 92: '{', 93: '|', 94: '}', 95: '~', 96: '<PADDING>', 97: '<END>'}\n{0: '<START>', 1: ' ', 2: '!', 3: '\"', 4: '#', 5: '$', 6: '%', 7: '&', 8: \"'\", 9: '(', 10: ')', 11: '*', 12: '+', 13: ',', 14: '-', 15: '.', 16: '/', 17: '0', 18: '1', 19: '2', 20: '3', 21: '4', 22: '5', 23: '6', 24: '7', 25: '8', 26: '9', 27: ':', 28: '<', 29: '=', 30: '>', 31: '?', 32: '@', 33: ';', 34: '[', 35: '\\\\', 36: ']', 37: '^', 38: '_', 39: '`', 40: 'a', 41: 'b', 42: 'c', 43: 'd', 44: 'e', 45: 'f', 46: 'g', 47: 'h', 48: 'i', 49: 'j', 50: 'k', 51: 'l', 52: 'm', 53: 'n', 54: 'o', 55: 'p', 56: 'q', 57: 'r', 58: 's', 59: 't', 60: 'u', 61: 'v', 62: 'w', 63: 'x', 64: 'y', 65: 'z', 66: 'A', 67: 'B', 68: 'C', 69: 'D', 70: 'E', 71: 'F', 72: 'G', 73: 'H', 74: 'I', 75: 'J', 76: 'K', 77: 'L', 78: 'M', 79: 'N', 80: 'O', 81: 'P', 82: 'Q', 83: 'R', 84: 'S', 85: 'T', 86: 'U', 87: 'V', 88: 'W', 89: 'X', 90: 'Y', 91: 'Z', 92: '{', 93: '|', 94: '}', 95: '~', 96: '<PADDING>', 97: '<END>'}\n","output_type":"stream"}]},{"cell_type":"code","source":"with open(hinglish_file, 'r', encoding='latin-1') as file:\n    hinglish_sentences = file.readlines()\nwith open(english_file, 'r', encoding='latin-1') as file:\n    english_sentences = file.readlines()\n    \n\n\nTOTAL_SENTENCES = 200000\n\ndef preprocess_sentence(sentence, vocabulary):\n    \n    sentence = ''.join(char for char in sentence if char in vocabulary)\n    return sentence\n\nhinglish_sentences = [preprocess_sentence(sentence, hinglish_vocabulary) for sentence in hinglish_sentences]\nenglish_sentences = [preprocess_sentence(sentence, english_vocabulary) for sentence in english_sentences]\n\nhinglish_sentences = [sentence.strip() for sentence in hinglish_sentences]\nenglish_sentences = [sentence.strip() for sentence in english_sentences if sentence.strip()]\n#print(kannada_sentences[:10])\n","metadata":{"id":"9SYGjRdoxRg-","execution":{"iopub.status.busy":"2024-05-05T04:50:17.279209Z","iopub.execute_input":"2024-05-05T04:50:17.279577Z","iopub.status.idle":"2024-05-05T04:50:19.407223Z","shell.execute_reply.started":"2024-05-05T04:50:17.279547Z","shell.execute_reply":"2024-05-05T04:50:19.406378Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"hinglish_sentences[:3]","metadata":{"id":"CUB-BkgFxXfM","outputId":"bcf7e19c-d1df-4b69-bdfa-eb74ac1a4338","execution":{"iopub.status.busy":"2024-05-05T04:50:19.408777Z","iopub.execute_input":"2024-05-05T04:50:19.409076Z","iopub.status.idle":"2024-05-05T04:50:19.415960Z","shell.execute_reply.started":"2024-05-05T04:50:19.409051Z","shell.execute_reply":"2024-05-05T04:50:19.414955Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"['mere timer ko roko',\n 'Kya hawaii me raining ho rahi hai?',\n 'Mere liye reminder set karo to wake up at 6:30 am tomorrow.']"},"metadata":{}}]},{"cell_type":"code","source":"english_sentences[:3]","metadata":{"id":"8OT-aznAxc5U","outputId":"716c4145-fdc2-4bb0-e883-c3dcad30c2da","execution":{"iopub.status.busy":"2024-05-05T04:50:20.318788Z","iopub.execute_input":"2024-05-05T04:50:20.319173Z","iopub.status.idle":"2024-05-05T04:50:20.325753Z","shell.execute_reply.started":"2024-05-05T04:50:20.319144Z","shell.execute_reply":"2024-05-05T04:50:20.324813Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"['Pause my timer .',\n 'Is it raining in Hawaii ?',\n 'Set a reminder for me to wake up at 630 am tomorrow .']"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nPERCENTILE = 97\nprint( f\"{PERCENTILE}th percentile length English: {np.percentile([len(x) for x in english_sentences], PERCENTILE)}\" )\nprint( f\"{PERCENTILE}th percentile length Hinglish: {np.percentile([len(x) for x in hinglish_sentences], PERCENTILE)}\" )\n","metadata":{"id":"h8VAutsTxlaR","outputId":"ff8fba72-020d-4f0c-b3c5-31c102b6fe9b","execution":{"iopub.status.busy":"2024-05-05T04:50:21.303322Z","iopub.execute_input":"2024-05-05T04:50:21.304065Z","iopub.status.idle":"2024-05-05T04:50:21.317447Z","shell.execute_reply.started":"2024-05-05T04:50:21.304032Z","shell.execute_reply":"2024-05-05T04:50:21.316388Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"97th percentile length English: 79.0\n97th percentile length Hinglish: 93.0\n","output_type":"stream"}]},{"cell_type":"code","source":"max_sequence_length = 200\n\ndef is_valid_tokens(sentence, vocab):\n    for token in list(set(sentence)):\n        if token not in vocab:\n            return False\n    return True\n\ndef is_valid_length(sentence, max_sequence_length):\n    return len(list(sentence)) < (max_sequence_length - 1) \n\nvalid_sentence_indicies = []\nl=min(len(english_sentences),len(hinglish_sentences))\nfor index in range(l):\n    english_sentence, hinglish_sentence = english_sentences[index], hinglish_sentences[index]\n    if is_valid_length(english_sentence, max_sequence_length) \\\n      and is_valid_length(hinglish_sentence, max_sequence_length) \\\n      and is_valid_tokens(english_sentence, english_vocabulary):\n        valid_sentence_indicies.append(index)\n\nprint(f\"Number of sentences: {len(english_sentences)}\")\nprint(f\"Number of valid sentences: {len(valid_sentence_indicies)}\")","metadata":{"id":"HG9ezqvaxl4b","outputId":"d13be774-ca07-4333-856e-76186f71caae","execution":{"iopub.status.busy":"2024-05-05T04:50:22.247942Z","iopub.execute_input":"2024-05-05T04:50:22.248351Z","iopub.status.idle":"2024-05-05T04:50:22.532344Z","shell.execute_reply.started":"2024-05-05T04:50:22.248323Z","shell.execute_reply":"2024-05-05T04:50:22.531432Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Number of sentences: 9506\nNumber of valid sentences: 9506\n","output_type":"stream"}]},{"cell_type":"code","source":"english_sentences = [english_sentences[i] for i in valid_sentence_indicies]\nhinglish_sentences = [hinglish_sentences[i] for i in valid_sentence_indicies]","metadata":{"id":"o80QDn4CxsV7","execution":{"iopub.status.busy":"2024-05-05T04:50:23.148831Z","iopub.execute_input":"2024-05-05T04:50:23.149530Z","iopub.status.idle":"2024-05-05T04:50:23.155209Z","shell.execute_reply.started":"2024-05-05T04:50:23.149499Z","shell.execute_reply":"2024-05-05T04:50:23.154267Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"english_sentences[:3]","metadata":{"id":"35xhLztQiLIQ","outputId":"aa70ad04-2e45-4c78-c852-61e92c51a96a","execution":{"iopub.status.busy":"2024-05-05T04:50:24.332935Z","iopub.execute_input":"2024-05-05T04:50:24.333317Z","iopub.status.idle":"2024-05-05T04:50:24.339586Z","shell.execute_reply.started":"2024-05-05T04:50:24.333281Z","shell.execute_reply":"2024-05-05T04:50:24.338593Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"['Pause my timer .',\n 'Is it raining in Hawaii ?',\n 'Set a reminder for me to wake up at 630 am tomorrow .']"},"metadata":{}}]},{"cell_type":"code","source":"import torch \nd_model = 512\nbatch_size = 128\nffn_hidden = 1024\nnum_heads = 8\ndrop_prob = 0.1\nnum_layers = 3\nmax_sequence_length = 200\neng_vocab_size = len(english_vocabulary)\n\ntransformer = Transformer(d_model, \n                          ffn_hidden,\n                          num_heads, \n                          drop_prob, \n                          num_layers, \n                          max_sequence_length,\n                          eng_vocab_size,\n                          hinglish_to_index,\n                          english_to_index,\n                          START_TOKEN, \n                          END_TOKEN, \n                          PADDING_TOKEN)\n","metadata":{"id":"xqOFnclmyxAE","execution":{"iopub.status.busy":"2024-05-05T04:50:25.395819Z","iopub.execute_input":"2024-05-05T04:50:25.396180Z","iopub.status.idle":"2024-05-05T04:50:25.617910Z","shell.execute_reply.started":"2024-05-05T04:50:25.396153Z","shell.execute_reply":"2024-05-05T04:50:25.617109Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"transformer","metadata":{"id":"Zc2hYQk9yxX0","outputId":"c060f588-6a2e-4179-9475-5acafd641f1f","execution":{"iopub.status.busy":"2024-05-05T04:50:26.342435Z","iopub.execute_input":"2024-05-05T04:50:26.342816Z","iopub.status.idle":"2024-05-05T04:50:26.350543Z","shell.execute_reply.started":"2024-05-05T04:50:26.342778Z","shell.execute_reply":"2024-05-05T04:50:26.349676Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"Transformer(\n  (encoder): Encoder(\n    (sentence_embedding): SentenceEmbedding(\n      (embedding): Embedding(98, 512)\n      (position_encoder): PositionalEncoding()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (layers): SequentialEncoder(\n      (0): EncoderLayer(\n        (attention): MultiHeadAttention(\n          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (norm1): LayerNormalization()\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (ffn): PositionwiseFeedForward(\n          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n          (relu): ReLU()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (norm2): LayerNormalization()\n        (dropout2): Dropout(p=0.1, inplace=False)\n      )\n      (1): EncoderLayer(\n        (attention): MultiHeadAttention(\n          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (norm1): LayerNormalization()\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (ffn): PositionwiseFeedForward(\n          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n          (relu): ReLU()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (norm2): LayerNormalization()\n        (dropout2): Dropout(p=0.1, inplace=False)\n      )\n      (2): EncoderLayer(\n        (attention): MultiHeadAttention(\n          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (norm1): LayerNormalization()\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (ffn): PositionwiseFeedForward(\n          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n          (relu): ReLU()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (norm2): LayerNormalization()\n        (dropout2): Dropout(p=0.1, inplace=False)\n      )\n    )\n  )\n  (decoder): Decoder(\n    (sentence_embedding): SentenceEmbedding(\n      (embedding): Embedding(98, 512)\n      (position_encoder): PositionalEncoding()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (layers): SequentialDecoder(\n      (0): DecoderLayer(\n        (self_attention): MultiHeadAttention(\n          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (layer_norm1): LayerNormalization()\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (encoder_decoder_attention): MultiHeadCrossAttention(\n          (kv_layer): Linear(in_features=512, out_features=1024, bias=True)\n          (q_layer): Linear(in_features=512, out_features=512, bias=True)\n          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (layer_norm2): LayerNormalization()\n        (dropout2): Dropout(p=0.1, inplace=False)\n        (ffn): PositionwiseFeedForward(\n          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n          (relu): ReLU()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (layer_norm3): LayerNormalization()\n        (dropout3): Dropout(p=0.1, inplace=False)\n      )\n      (1): DecoderLayer(\n        (self_attention): MultiHeadAttention(\n          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (layer_norm1): LayerNormalization()\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (encoder_decoder_attention): MultiHeadCrossAttention(\n          (kv_layer): Linear(in_features=512, out_features=1024, bias=True)\n          (q_layer): Linear(in_features=512, out_features=512, bias=True)\n          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (layer_norm2): LayerNormalization()\n        (dropout2): Dropout(p=0.1, inplace=False)\n        (ffn): PositionwiseFeedForward(\n          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n          (relu): ReLU()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (layer_norm3): LayerNormalization()\n        (dropout3): Dropout(p=0.1, inplace=False)\n      )\n      (2): DecoderLayer(\n        (self_attention): MultiHeadAttention(\n          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (layer_norm1): LayerNormalization()\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (encoder_decoder_attention): MultiHeadCrossAttention(\n          (kv_layer): Linear(in_features=512, out_features=1024, bias=True)\n          (q_layer): Linear(in_features=512, out_features=512, bias=True)\n          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (layer_norm2): LayerNormalization()\n        (dropout2): Dropout(p=0.1, inplace=False)\n        (ffn): PositionwiseFeedForward(\n          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n          (relu): ReLU()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (layer_norm3): LayerNormalization()\n        (dropout3): Dropout(p=0.1, inplace=False)\n      )\n    )\n  )\n  (linear): Linear(in_features=512, out_features=98, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\n\nclass TextDataset(Dataset):\n\n    def __init__(self, hinglish_sentences, english_sentences):\n        self.hinglish_sentences = hinglish_sentences\n        self.english_sentences = english_sentences\n\n    def __len__(self):\n        return len(self.hinglish_sentences)\n\n    def __getitem__(self, idx):\n        return self.hinglish_sentences[idx], self.english_sentences[idx]","metadata":{"id":"asUJX-STy7fg","execution":{"iopub.status.busy":"2024-05-04T04:07:53.509622Z","iopub.execute_input":"2024-05-04T04:07:53.509981Z","iopub.status.idle":"2024-05-04T04:07:53.515797Z","shell.execute_reply.started":"2024-05-04T04:07:53.509954Z","shell.execute_reply":"2024-05-04T04:07:53.514907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = TextDataset(hinglish_sentences, english_sentences)","metadata":{"id":"-auNWjkdzDge","execution":{"iopub.status.busy":"2024-05-04T04:07:54.962136Z","iopub.execute_input":"2024-05-04T04:07:54.962991Z","iopub.status.idle":"2024-05-04T04:07:54.967265Z","shell.execute_reply.started":"2024-05-04T04:07:54.962958Z","shell.execute_reply":"2024-05-04T04:07:54.966197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(dataset[:3])","metadata":{"execution":{"iopub.status.busy":"2024-05-04T04:07:56.757095Z","iopub.execute_input":"2024-05-04T04:07:56.757448Z","iopub.status.idle":"2024-05-04T04:07:56.762467Z","shell.execute_reply.started":"2024-05-04T04:07:56.757421Z","shell.execute_reply":"2024-05-04T04:07:56.761427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(dataset)","metadata":{"id":"roH2A4m4zF4z","outputId":"f4353aa8-2f37-43b6-be0f-12aab9a35145","execution":{"iopub.status.busy":"2024-05-04T04:07:58.220572Z","iopub.execute_input":"2024-05-04T04:07:58.220990Z","iopub.status.idle":"2024-05-04T04:07:58.226931Z","shell.execute_reply.started":"2024-05-04T04:07:58.220960Z","shell.execute_reply":"2024-05-04T04:07:58.225998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset[1]","metadata":{"id":"HGeHNlzozIGF","outputId":"ec3596fe-feee-426c-dce8-373fb07080fd","execution":{"iopub.status.busy":"2024-05-04T04:07:59.456339Z","iopub.execute_input":"2024-05-04T04:07:59.456917Z","iopub.status.idle":"2024-05-04T04:07:59.462520Z","shell.execute_reply.started":"2024-05-04T04:07:59.456885Z","shell.execute_reply":"2024-05-04T04:07:59.461628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(dataset, batch_size)\niterator = iter(train_loader)","metadata":{"id":"5YDttjQ0zMrv","execution":{"iopub.status.busy":"2024-05-04T04:08:00.482717Z","iopub.execute_input":"2024-05-04T04:08:00.483095Z","iopub.status.idle":"2024-05-04T04:08:00.493241Z","shell.execute_reply.started":"2024-05-04T04:08:00.483066Z","shell.execute_reply":"2024-05-04T04:08:00.492326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for batch_num, batch in enumerate(iterator):\n    print(batch)\n    if batch_num > 3:\n        break","metadata":{"id":"9EnjHKB1zM8Y","outputId":"1a825e56-6706-46ee-85b5-ed7f0ac657fb","execution":{"iopub.status.busy":"2024-05-04T04:08:01.834038Z","iopub.execute_input":"2024-05-04T04:08:01.834397Z","iopub.status.idle":"2024-05-04T04:08:01.842363Z","shell.execute_reply.started":"2024-05-04T04:08:01.834370Z","shell.execute_reply":"2024-05-04T04:08:01.841406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch import nn\n\ncriterian = nn.CrossEntropyLoss(ignore_index=english_to_index[PADDING_TOKEN],\n                                reduction='none')\n\n# When computing the loss, we are ignoring cases when the label is the padding token\nfor params in transformer.parameters():\n    if params.dim() > 1:\n        nn.init.xavier_uniform_(params)\n\noptim = torch.optim.Adam(transformer.parameters(), lr=1e-4)\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')","metadata":{"id":"XnanjzqtzQi8","execution":{"iopub.status.busy":"2024-05-04T04:08:40.182435Z","iopub.execute_input":"2024-05-04T04:08:40.183139Z","iopub.status.idle":"2024-05-04T04:08:42.911994Z","shell.execute_reply.started":"2024-05-04T04:08:40.183108Z","shell.execute_reply":"2024-05-04T04:08:42.911007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NEG_INFTY = -1e9\n\ndef create_masks(hing_batch, eng_batch):\n    num_sentences = len(hing_batch)\n    look_ahead_mask = torch.full([max_sequence_length, max_sequence_length] , True)\n    look_ahead_mask = torch.triu(look_ahead_mask, diagonal=1)\n    encoder_padding_mask = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n    decoder_padding_mask_self_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n    decoder_padding_mask_cross_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n\n    for idx in range(num_sentences):\n      hing_sentence_length, eng_sentence_length = len(hing_batch[idx]), len(eng_batch[idx])\n      hing_chars_to_padding_mask = np.arange(hing_sentence_length + 1, max_sequence_length)\n      eng_chars_to_padding_mask = np.arange(eng_sentence_length + 1, max_sequence_length)\n      encoder_padding_mask[idx, :, hing_chars_to_padding_mask] = True\n      encoder_padding_mask[idx, hing_chars_to_padding_mask, :] = True\n      decoder_padding_mask_self_attention[idx, :, eng_chars_to_padding_mask] = True\n      decoder_padding_mask_self_attention[idx, eng_chars_to_padding_mask, :] = True\n      decoder_padding_mask_cross_attention[idx, :, hing_chars_to_padding_mask] = True\n      decoder_padding_mask_cross_attention[idx, eng_chars_to_padding_mask, :] = True\n\n    encoder_self_attention_mask = torch.where(encoder_padding_mask, NEG_INFTY, 0)\n    decoder_self_attention_mask =  torch.where(look_ahead_mask + decoder_padding_mask_self_attention, NEG_INFTY, 0)\n    decoder_cross_attention_mask = torch.where(decoder_padding_mask_cross_attention, NEG_INFTY, 0)\n    return encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask","metadata":{"id":"_saWU5QmVem2","execution":{"iopub.status.busy":"2024-05-04T04:08:42.913993Z","iopub.execute_input":"2024-05-04T04:08:42.914540Z","iopub.status.idle":"2024-05-04T04:08:42.927064Z","shell.execute_reply.started":"2024-05-04T04:08:42.914499Z","shell.execute_reply":"2024-05-04T04:08:42.925667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformer.train()\ntransformer.to(device)\ntotal_loss = 0\nnum_epochs = 200\n\nfor epoch in range(num_epochs):\n    print(f\"Epoch {epoch}\")\n    iterator = iter(train_loader)\n    for batch_num, batch in enumerate(iterator):\n        transformer.train()\n        hing_batch, eng_batch = batch\n        encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(hing_batch, eng_batch)\n        optim.zero_grad()\n        eng_predictions = transformer(hing_batch,\n                                     eng_batch,\n                                     encoder_self_attention_mask.to(device), \n                                     decoder_self_attention_mask.to(device), \n                                     decoder_cross_attention_mask.to(device),\n                                     enc_start_token=False,\n                                     enc_end_token=False,\n                                     dec_start_token=True,\n                                     dec_end_token=True)\n        labels = transformer.decoder.sentence_embedding.batch_tokenize(eng_batch, start_token=False, end_token=True)\n        loss = criterian(\n            eng_predictions.view(-1, eng_vocab_size).to(device),\n            labels.view(-1).to(device)\n        ).to(device)\n        valid_indicies = torch.where(labels.view(-1) == english_to_index[PADDING_TOKEN], False, True)\n        loss = loss.sum() / valid_indicies.sum()\n        loss.backward()\n        optim.step()\n        #train_losses.append(loss.item())\n        if batch_num % 100 == 0:\n            print(f\"Iteration {batch_num} : {loss.item()}\")\n            print(f\"Hinglish: {hing_batch[0]}\")\n            print(f\"English Translation: {eng_batch[0]}\")\n            eng_sentence_predicted = torch.argmax(eng_predictions[0], axis=1)\n            predicted_sentence = \"\"\n            for idx in eng_sentence_predicted:\n              if idx == english_to_index[END_TOKEN]:\n                break\n              predicted_sentence += index_to_english[idx.item()]\n            print(f\"English Prediction: {predicted_sentence}\")\n\n\n            transformer.eval()\n            eng_sentence = (\"\",)\n            hing_sentence = (\"mom ki job ko sabse chota raasta kya hai?\",)\n            for word_counter in range(max_sequence_length):\n                encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask= create_masks(hing_sentence, eng_sentence)\n                predictions = transformer(hing_sentence,\n                                          eng_sentence,\n                                          encoder_self_attention_mask.to(device), \n                                          decoder_self_attention_mask.to(device), \n                                          decoder_cross_attention_mask.to(device),\n                                          enc_start_token=False,\n                                          enc_end_token=False,\n                                          dec_start_token=True,\n                                          dec_end_token=False)\n                next_token_prob_distribution = predictions[0][word_counter] # not actual probs\n                next_token_index = torch.argmax(next_token_prob_distribution).item()\n                next_token = index_to_english[next_token_index]\n                eng_sentence = (eng_sentence[0] + next_token, )\n                if next_token == END_TOKEN:\n                  break\n            \n            print(f\"Evaluation translation (What the shortest route to Mom job ?) : {eng_sentence}\")\n            print(\"-------------------------------------------\")","metadata":{"id":"ju59VDGLuOqf","outputId":"0ad34e31-521a-4ca2-f444-26b5374946f6","execution":{"iopub.status.busy":"2024-05-04T04:08:44.496373Z","iopub.execute_input":"2024-05-04T04:08:44.496717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference","metadata":{"id":"1nosVPGVijId"}},{"cell_type":"code","source":"transformer.eval()\ndef translate(hing_sentence):\n  hing_sentence = (hing_sentence,)\n  eng_sentence = (\"\",)\n  for word_counter in range(max_sequence_length):\n    encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask= create_masks(hing_sentence, eng_sentence)\n    predictions = transformer(hing_sentence,\n                              eng_sentence,\n                              encoder_self_attention_mask.to(device), \n                              decoder_self_attention_mask.to(device), \n                              decoder_cross_attention_mask.to(device),\n                              enc_start_token=False,\n                              enc_end_token=False,\n                              dec_start_token=True,\n                              dec_end_token=False)\n    next_token_prob_distribution = predictions[0][word_counter]\n    next_token_index = torch.argmax(next_token_prob_distribution).item()\n    next_token = index_to_english[next_token_index]\n    eng_sentence = (eng_sentence[0] + next_token, )\n    if next_token == END_TOKEN:\n      break\n  return eng_sentence[0]","metadata":{"id":"ZOQe-juylBiJ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"translation = translate(\"terry ko message kariye ki i did hear from Joe and he is coming to the party with me on sunday\")\nprint(translation)\n","metadata":{"id":"BDVH_YsxlK6q","outputId":"83c47f99-53c0-4c2d-c26a-aaa426f50563","execution":{"iopub.status.busy":"2024-05-03T14:56:47.663729Z","iopub.execute_input":"2024-05-03T14:56:47.664373Z","iopub.status.idle":"2024-05-03T14:56:47.691693Z","shell.execute_reply.started":"2024-05-03T14:56:47.664340Z","shell.execute_reply":"2024-05-03T14:56:47.690366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"translation = translate(\"this weekend big Sur me weather kesa rahega ?\")\nprint(translation)","metadata":{"id":"l9yfawBnul0W","outputId":"d9e6e6b7-683b-45f9-f013-c53c31038306","execution":{"iopub.status.busy":"2024-04-19T05:29:48.783881Z","iopub.status.idle":"2024-04-19T05:29:48.784179Z","shell.execute_reply.started":"2024-04-19T05:29:48.784030Z","shell.execute_reply":"2024-04-19T05:29:48.784043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"translation = translate(\"august 30th ke liye subha 7 bajhe se subah 8 bajhe tak ka reminder set kare\")\nprint(translation)\n","metadata":{"id":"jpdYBk5-urcQ","outputId":"ca7249c5-efda-4f41-f052-ecef9691be82","execution":{"iopub.status.busy":"2024-04-19T05:29:48.785090Z","iopub.status.idle":"2024-04-19T05:29:48.785412Z","shell.execute_reply.started":"2024-04-19T05:29:48.785237Z","shell.execute_reply":"2024-04-19T05:29:48.785249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"translation = translate(\"friday dopahar ko lawyer ko naye ghar ke liye contracts submit karne ke liye reminder set karen\")\nprint(translation)\n","metadata":{"id":"Ni9e2UYUuxi3","outputId":"b93968e6-3f12-4794-b277-3a3821af221e","execution":{"iopub.status.busy":"2024-05-05T00:55:29.173593Z","iopub.execute_input":"2024-05-05T00:55:29.174676Z","iopub.status.idle":"2024-05-05T00:55:29.504148Z","shell.execute_reply.started":"2024-05-05T00:55:29.174625Z","shell.execute_reply":"2024-05-05T00:55:29.502813Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m translation \u001b[38;5;241m=\u001b[39m \u001b[43mtranslate\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfriday dopahar ko lawyer ko naye ghar ke liye contracts submit karne ke liye reminder set karen\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(translation)\n","\u001b[0;31mNameError\u001b[0m: name 'translate' is not defined"],"ename":"NameError","evalue":"name 'translate' is not defined","output_type":"error"}]},{"cell_type":"code","source":"translation = translate(\"mujhe doraville pahuchne mei kitni der lagegi agar mai abhi nikalta hoon\")\nprint(translation)","metadata":{"id":"sJuJKHqFldW3","outputId":"71aa2c6c-ec77-4b02-d39b-bd724012fb53","execution":{"iopub.status.busy":"2024-04-19T05:29:48.789934Z","iopub.status.idle":"2024-04-19T05:29:48.790439Z","shell.execute_reply.started":"2024-04-19T05:29:48.790160Z","shell.execute_reply":"2024-04-19T05:29:48.790190Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"translation = translate(\"ek happy song bajao\")\nprint(translation)","metadata":{"id":"SxHC4Lirlfu8","outputId":"5a3ca401-abac-41af-d9db-99fb7a57fe00","execution":{"iopub.status.busy":"2024-04-19T05:29:48.792150Z","iopub.status.idle":"2024-04-19T05:29:48.792498Z","shell.execute_reply.started":"2024-04-19T05:29:48.792316Z","shell.execute_reply":"2024-04-19T05:29:48.792329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\n\n# Define your validation dataset class\nclass ValidationDataset(Dataset):\n    def __init__(self, hinglish_file, english_file):\n        # Read data from files\n        with open(hinglish_file, 'r', encoding='utf-8') as f:\n            self.hinglish_sentences = f.readlines()\n        with open(english_file, 'r', encoding='utf-8') as f:\n            self.english_sentences = f.readlines()\n\n    def __len__(self):\n        return len(self.hinglish_sentences)\n\n    def __getitem__(self, index):\n        return self.hinglish_sentences[index], self.english_sentences[index]\n\n# Paths to the validation Hinglish and English datasets\nhinglish_file_path = \"/kaggle/input/validation/Val_Hinglish.txt\"\nenglish_file_path = \"/kaggle/input/validation/Val_English.txt\"\n\n\n# Define batch size\nbatch_size = 32\n\n# Instantiate the validation DataLoader\nvalidation_dataset = ValidationDataset(hinglish_file_path, english_file_path)\nvalidation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-04T15:21:47.198332Z","iopub.execute_input":"2024-05-04T15:21:47.199044Z","iopub.status.idle":"2024-05-04T15:21:47.232753Z","shell.execute_reply.started":"2024-05-04T15:21:47.199010Z","shell.execute_reply":"2024-05-04T15:21:47.231962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk.translate.bleu_score as bleu\n\ndef evaluate_model(model, val_loader):\n    translations = []\n    references = []\n\n    model.eval()\n    with torch.no_grad():\n        for hing_batch, eng_batch in val_loader:\n            for hing_sentence in hing_batch:\n                # Translate Hinglish sentence to English\n#                 print(hing_sentence[:-1])\n#                 print(\"**\")\n                eng_sentence = translate( hing_sentence[:-1])\n#                 eng_sentence=\"Hi\"\n                \n                translations.append(eng_sentence[:-1])  \n            \n            # Collect reference English sentences and convert to lowercase\n            references.extend([ref for ref in eng_batch])\n    \n    # Calculate BLEU score\n    bleu_score = calculate_bleu(translations, references)\n    print(\"BLEU Score:\", bleu_score)\n\ndef calculate_bleu(translations, references):\n    # BLEU score calculation\n    bleu_score = bleu.corpus_bleu([[ref.split()] for ref in references], [trans.split() for trans in translations])\n    return bleu_score\n\n# Call the evaluation function with your trained model and validation DataLoader\nevaluate_model(transformer, validation_loader)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-04T15:24:16.136794Z","iopub.execute_input":"2024-05-04T15:24:16.137134Z","iopub.status.idle":"2024-05-04T15:24:16.245553Z","shell.execute_reply.started":"2024-05-04T15:24:16.137094Z","shell.execute_reply":"2024-05-04T15:24:16.244649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}